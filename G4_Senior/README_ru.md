# Сценарий

Настроить инкрементальную загрузку всех таблиц из всех источников в исторические таблицы DWH с SCD2. Учесть, что данные могут обновляться с некоторой глубиной в прошлом.

Настроить логирование и автотесты, отбрасывать несогласованные данные в аналог dead letter queue, руководствуясь принципом Write - Audit - Publish.

Ограничив в docker compose af-scheduler 4 cores 4GB RAM, провести "нагрузочное тестирование" и определить максимальную среднюю пропускную способность в строках за 10 минут, которые может загрузить написанное решение. Допустим, что обновляться может до 60% от ```insert_rows_per_tick``` за тик. Используй параметры генератора, чтобы изменять скорость появления данных на источнике.

<details>
<summary>Подсказки</summary>
<br>

* Чтобы не нарушить логику, сохраняй соотношение значений генератора STOP_GENERATOR_AFTER_SEC > DELETE_OLDER_THAN_SEC > UPDATE_NOT_OLDER_THAN_SEC > TICK_INTERVAL_SEC.
</details>
<br>

Definition of done:
* 3 таблицы из двух источников грузятся в DWH.
* Решение должно легко расширяться под новые таблицы и источники.
* История в строках хранится с точностью до секунды (SCD2 через timestamp).
* Захватываются последние изменения строки в пределах одного PK перед моментом очередного забора пакета данных, промежуточные пропускаются, -- это общая проблема batch загрузок, допускается..
* Задержка появления данных в DWH до 5 минут при стандартных настройках генератора.
* Для каждого FK в таблице фактов существует PK в таблице измерений, несогласованные данные сохранены в таблицах "сбоку".
* Решение оптимизировано под большую нагрузку, известно среднее число строк, которое через себя может пропускать система в 10 минут.

Бонус:
* Если запись с отброшенным на моменте Audit айдишником приедет с одной из следующих загрузок, нужно эти отброшенные строки опубликовать в основной таблице.